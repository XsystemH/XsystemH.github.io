<head>
<title>HAJL.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
    // 配置MathJax
    MathJax = {
        tex: {
            inlineMath: [['\\(', '\\)']],
            processEscapes: true
        },
        options: {
            ignoreHtmlClass: '.*',
            processHtmlClass: 'mathjax'
        }
    };
</script>

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 25%;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="haji-reading-notes">HAJI Reading Notes</h1>
<p><a href="https://arxiv.org/abs/2407.00299">Arxiv</a></p>
<h2 id="backgrounds">Backgrounds</h2>
<ul>
<li>Classic Paradigm Challenges:
<ol>
<li><strong>Persistent Error</strong> significantly degrade the teleoperation</li>
<li><strong>Discrepancies</strong> between the structures of human hands and robot end-effectors</li>
<li><strong>The Lack of Haptic Feedback</strong> during contact-rich manipulation (Haptic: 触觉)</li>
</ol>
</li>
<li>So, need human efforts and high-quality datasets.</li>
</ul>
<h2 id="intro">Intro</h2>
<p><em>In data-collection, how to make human effort less while improving the data quality?</em></p>
<p><strong>HAJI</strong>:</p>
<ol>
<li>Preferentially capture <code>intentions</code>.</li>
<li>Agent to ensure <code>motion stability</code> and <code>interpolate</code>? the details.</li>
<li>Shared control(with a growing ratio).</li>
</ol>
<p><img src="img/joint-learning.png" alt=""></p>
<p>Acchived a 30% increase in data collection success rate and double the <code>collection speed</code>.</p>
<pre><code>My question about this part: how to define and measure the collection speed?
</code></pre>
<h2 id="method">Method</h2>
<h3 id="in-brief">In Brief</h3>
<p><strong>Stage1</strong>: Human control as an initial but insufficient training dataset.</p>
<p><strong>Stage2</strong>: Train a diffusion-model-based assistive agent, establish shared control.</p>
<p>Growing with more data coming in and if sufficient able to full auto.</p>
<pre><code>How diffusion be used to control a robot? What the outputs of this model be like?

Answer(from below parts): generate the action for agents
</code></pre>
<h3 id="a-preliminary">A. Preliminary</h3>
<p><strong>DDPM</strong></p>
<ol>
<li><strong>Forward</strong>: Adding Guassian noise to \(x^0\) according to \(\beta_{1:K}\) by \(x_k = \sqrt{\alpha_k}x_{k-1} + \sqrt{1-\alpha_k}\varepsilon\), \(\varepsilon \sim \mathcal{N}(\textbf{0, I})\), \(\alpha_k = 1 - \beta_k\)</li>
<li><strong>Reverse Process</strong>: \(p_\theta(x^0)=\int p(x^K)\prod p_\theta(x^{k-1}|x^k)dx^{1:k}\), where \(p_\theta(x^{k-1}|x^k)=\mathcal{N}(\mu_\theta(x^k, k), \sum(x^k, k))\).</li>
<li><strong>Loss Func</strong>: \(\mathcal{L}:=\mathbb{E}_{k,x_0,\varepsilon\sim\mathcal{N}(\textbf{0,I})}[||\varepsilon-\varepsilon_\theta(x_k(x_0,\varepsilon),k)||^2_2]\).</li>
<li><strong>Generate \(x_0\)</strong>: \(x_{k-1}=\mu_\theta(x_k, k) + \sigma_k z\), \(z \sim \mathcal{N}(\textbf{0,I})\) (sampled recursively).</li>
<li>With collected trajaectory \({(s_i,a_i)}^T_{i=0}\), \(\mathcal{L}:=\mathbb{E}_{k,(s_i,a_i),\varepsilon\sim\mathcal{N}(\textbf{0,I})}[||\varepsilon-\varepsilon_\theta(a_i+\varepsilon,s_i,k)||^2_2]\).</li>
</ol>
<pre class="hljs"><code><div>Q: What is x_k(x_0,\varepsilon)?
A: A function to get x_k from x_0 with \varepsilon?
</div></code></pre>
<h3 id="b-teleoperation-system">B. Teleoperation System</h3>
<p><img src="/img/TeleSys.jpg" alt=""></p>
<p>We can get the human collected demonstration \({(s_i,a_i)}^T_{i=0}\), \(s \in \mathbb{R}^n\) is the robot state.</p>
<pre class="hljs"><code><div>Q: What state exactly?
</div></code></pre>
<h3 id="c-diffusion-model-based-assistive-agent">C. Diffusion-Model-Based Assistive Agent</h3>
<p><strong>Agent</strong>: \(a=f(a^k|s,k)\).</p>
<p>During <strong>Data Collection</strong>, \(a^s=\gamma a^h + (1-\gamma)a^r\), where \(a^r\) is generated by agent \(a^h\) is human action, and \(a^s\) is <code>Shared Control Action</code>.</p>
<p><img src="img/sca.png" alt=""></p>
<p><strong>Diffussion</strong>: forward \(a^k=a^h+\varepsilon^k\), backward \(a^s=f(a^k|s,k)\)</p>
<p>Increase \(\gamma\) as \(k\) grow. When \(\gamma = 1.0\) \(a^s\) turn to \(a^r\), full robot auto action.</p>
<pre class="hljs"><code><div>A little bit confused about H and D.
</div></code></pre>
<h3 id="d-integrating-data-collection-and-manipulation-learning">D. Integrating Data Collection and Manipulation Learning</h3>
<pre class="hljs"><code><div>Q: May I see the code?
</div></code></pre>
<h2 id="experiments">Experiments</h2>
<h3 id="a-tasks">A. Tasks</h3>
<p>6</p>
<pre class="hljs"><code><div>Q: What is in D? Is there only one movement for a perticular task? i.e. did we trained 6 agent? Or just one for all the tasks.
</div></code></pre>
<h3 id="b-efficiency-of-data-collection">B. Efficiency of Data Collection</h3>
<p>&quot;collect as much data as possible within three minutes&quot;</p>
<pre class="hljs"><code><div>Q: Is this definition rigorous enough?
</div></code></pre>
<p><strong>Evaluate</strong>:</p>
<ol>
<li><strong>Success Rate</strong>: How to tell?</li>
<li><strong>Horizon Length</strong>: Steps per Sample.</li>
<li><strong>Collection Speed</strong>: Samples per Hour.</li>
</ol>
<h3 id="c-quantitative-evaluation">C. Quantitative Evaluation</h3>
<p>For about half of my reading time, I was continuesly wondering about the meaning of training such a model as we can make the robot finish the task with our training data only. From Fig.4, I finally realized that the control process is in real time which means, after training, the human operator could be abstract, and robot will act base on the abstract instructions. This would save much time.
<code>Is this understanding right?</code></p>
<p><img src="img/fig4.png" alt=""></p>
<p>But here comes another question, in III-B, we have \(a^s=\gamma a^h + (1-\gamma)a^r\).</p>
<pre class="hljs"><code><div>Q1: Is this a simple weighted mean of h and r? If so, is this weighted average the average on the motion path coordinates? Intuitively imagine, does this seem unrealistic? Or is this just an abstract expression?

Q2(If 6 tasks are trained together): When \gamma=1, what will it do? Is there an input of environment(which I didn't find)?

Q3(If 6 tasks are not trained together): What will happen if trained together?
</div></code></pre>
<p>E. Real World Experiment</p>
<h2 id="appendix">Appendix</h2>
<h3 id="i-implementation-details">I. IMPLEMENTATION DETAILS</h3>
<h4 id="c-diffusion-model-based-assistive-agent">C. Diffusion-Model-Based Assistive Agent</h4>
<pre class="hljs"><code><div>MLP + Diffusion, How are they connected?
</div></code></pre>
<h3 id="ii-experiment-setups">II. EXPERIMENT SETUPS</h3>
<h4 id="c-real-world-experiment">C. Real World Experiment</h4>
<p>Our input has changed from the original hand states and object states to the position and orientation of the robot arm end effector, as well as images from the first-person and third-person perspectives.</p>
<pre class="hljs"><code><div>I didn't find where to input these things.
</div></code></pre>

</body>
</html>

# HAJI Reading Notes

[Arxiv](https://arxiv.org/abs/2407.00299)

## Backgrounds

- Classic Paradigm Challenges:
  1. **Persistent Error** significantly degrade the teleoperation
  2. **Discrepancies** between the structures of human hands and robot end-effectors
  3. **The Lack of Haptic Feedback** during contact-rich manipulation (Haptic: è§¦è§‰)
- So, need human efforts and high-quality datasets.

## Intro

*In data-collection, how to make human effort less while improving the data quality?*

**HAJI**:
  1. Preferentially capture `intentions`.
  2. Agent to ensure `motion stability` and `interpolate`? the details.
  3. Shared control(with a growing ratio).

![](img/joint-learning.png)

Acchived a 30% increase in data collection success rate and double the `collection speed`.

    My question about this part: how to define and measure the collection speed?

## Method

### In Brief

**Stage1**: Human control as an initial but insufficient training dataset.

**Stage2**: Train a diffusion-model-based assistive agent, establish shared control.

Growing with more data coming in and if sufficient able to full auto.

    How diffusion be used to control a robot? What the outputs of this model be like?

    Answer(from below parts): generate the action for agents

### A. Preliminary

**DDPM**
1. **Forward**: Adding Guassian noise to $x^0$ according to $\beta_{1:K}$ by $x_k = \sqrt{\alpha_k}x_{k-1} + \sqrt{1-\alpha_k}\varepsilon$, $\varepsilon \sim \mathcal{N}(\textbf{0, I})$, $\alpha_k = 1 - \beta_k$
2. **Reverse Process**: $p_\theta(x^0)=\int p(x^K)\prod p_\theta(x^{k-1}|x^k)dx^{1:k}$, where $p_\theta(x^{k-1}|x^k)=\mathcal{N}(\mu_\theta(x^k, k), \sum(x^k, k))$.
3. **Loss Func**: $\mathcal{L}:=\mathbb{E}\_{k,x_0,\varepsilon\sim\mathcal{N}(\textbf{0,I})}[||\varepsilon-\varepsilon_\theta(x_k(x_0,\varepsilon),k)||^2_2]$.
4. **Generate $x_0$**: $x_{k-1}=\mu_\theta(x_k, k) + \sigma_k z$, $z \sim \mathcal{N}(\textbf{0,I})$ (sampled recursively).
5. With collected trajaectory $\{(s_i,a_i)\}^T_{i=0}$, $\mathcal{L}:=\mathbb{E}\_{k,(s_i,a_i),\varepsilon\sim\mathcal{N}(\textbf{0,I})}[||\varepsilon-\varepsilon_\theta(a_i+\varepsilon,s_i,k)||^2_2]$.

```
Q: What is x_k(x_0,\varepsilon)?
A: A function to get x_k from x_0 with \varepsilon?
```

### B. Teleoperation System

![](/img/TeleSys.jpg)

We can get the human collected demonstration $\{(s_i,a_i)\}^T_{i=0}$, $s \in \mathbb{R}^n$ is the robot state.

```
Q: What state exactly?
```

### C. Diffusion-Model-Based Assistive Agent

**Agent**: $a=f(a^k|s,k)$.

During **Data Collection**, $a^s=\gamma a^h + (1-\gamma)a^r$, where $a^r$ is generated by agent $a^h$ is human action, and $a^s$ is `Shared Control Action`.

![](img/sca.png)

**Diffussion**: forward $a^k=a^h+\varepsilon^k$, backward $a^s=f(a^k|s,k)$

Increase $\gamma$ as $k$ grow. When $\gamma = 1.0$ $a^s$ turn to $a^r$, full robot auto action.

```
A little bit confused about H and D.
```

### D. Integrating Data Collection and Manipulation Learning

```
Q: May I see the code?
```

## Thinking

To be continued... (25/3/18 2:21 a.m. ðŸ˜´)